{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03199ad3",
   "metadata": {},
   "source": [
    "# Challenge 2: Reverse Transactions Analyzer (Gemini Version)\n",
    "\n",
    "This notebook implements an AI solution for the \"Reverse Transactions\" category of the \"Strengthening the Adoption of Standards in Islamic Finance with Artificial Intelligence\" Hackathon.\n",
    "\n",
    "## Objective\n",
    "Given \"out-of-context\" financial entries (journal entries and brief context), our AI solution will identify the relevant AAOIFI Financial Accounting Standard(s) (FAS) that govern such transactions. If multiple FAS are possible, the system provides a weighted probability and reasoning.\n",
    "\n",
    "## Approach\n",
    "1. Process and index the AAOIFI standards (FAS and SS) using RAG techniques with Google's Gemini embedding model\n",
    "2. Create a specialized prompt engineering system for reverse transaction analysis \n",
    "3. Provide weighted probability estimations for applicable standards\n",
    "4. Justify the analysis with references to specific sections of the standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2511c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import pdfplumber\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import json\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Check if GOOGLE_API_KEY is set\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    raise ValueError(\"GOOGLE_API_KEY environment variable is not set. Please set it to use Gemini models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e71a5e9",
   "metadata": {},
   "source": [
    "## Step 1: Data Extraction from FAS and SS Standards\n",
    "First, we'll extract text from the relevant AAOIFI standards documents (FAS and SS). These documents contain the rules and guidelines that determine the appropriate accounting treatments for various Islamic finance transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d232a8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted text from FAS 10 & SS 11.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted text from FAS10.PDF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted text from FAS28.PDF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted text from FAS32.pdf\n",
      "Successfully extracted text from FAS4.PDF\n",
      "Successfully extracted text from FAS4.PDF\n",
      "Successfully extracted text from FAS7.PDF\n",
      "Successfully extracted text from FAS7.PDF\n",
      "Successfully extracted text from SS10.pdf\n",
      "Successfully extracted text from SS10.pdf\n",
      "Successfully extracted text from SS12.pdf\n",
      "Successfully extracted text from SS8.pdf\n",
      "Successfully extracted text from SS9.pdf\n",
      "\n",
      "Total documents processed: 10\n"
     ]
    }
   ],
   "source": [
    "# Function to extract text from PDF documents\n",
    "def extract_pdf_text(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\"\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {pdf_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Get all PDF files from the data directory\n",
    "data_dir = \"../data\"\n",
    "pdf_files = [f for f in os.listdir(data_dir) if f.endswith('.pdf') or f.endswith('.PDF')]\n",
    "\n",
    "# Extract text from each PDF\n",
    "documents = []\n",
    "for pdf_file in pdf_files:\n",
    "    pdf_path = os.path.join(data_dir, pdf_file)\n",
    "    text = extract_pdf_text(pdf_path)\n",
    "    if text:\n",
    "        documents.append({\n",
    "            \"source\": pdf_file,\n",
    "            \"text\": text\n",
    "        })\n",
    "        print(f\"Successfully extracted text from {pdf_file}\")\n",
    "    else:\n",
    "        print(f\"Failed to extract text from {pdf_file}\")\n",
    "\n",
    "print(f\"\\nTotal documents processed: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1447ea7",
   "metadata": {},
   "source": [
    "## Step 2: Text Preprocessing and Chunking\n",
    "To optimize the retrieval process, we need to divide the document text into smaller, meaningful chunks. This enables more precise matching and retrieval when handling specific queries about accounting standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d13a2ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 1130\n"
     ]
    }
   ],
   "source": [
    "# Initialize text splitter for chunking\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # Larger chunks to capture more context\n",
    "    chunk_overlap=200,  # Significant overlap to preserve context across chunks\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# Process documents and create chunks with metadata\n",
    "chunks = []\n",
    "for doc in documents:\n",
    "    for i, chunk in enumerate(splitter.split_text(doc[\"text\"])):\n",
    "        # Extract standard number from filename if possible\n",
    "        standard_match = re.search(r'(FAS|SS)[\\s_-]*(\\d+)', doc[\"source\"], re.IGNORECASE)\n",
    "        standard_type = standard_match.group(1).upper() if standard_match else \"Unknown\"\n",
    "        standard_number = standard_match.group(2) if standard_match else \"Unknown\"\n",
    "        \n",
    "        chunks.append({\n",
    "            \"source\": doc[\"source\"],\n",
    "            \"text\": chunk,\n",
    "            \"chunk_id\": i,\n",
    "            \"standard_type\": standard_type,\n",
    "            \"standard_number\": standard_number\n",
    "        })\n",
    "\n",
    "print(f\"Total chunks created: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0383e75f",
   "metadata": {},
   "source": [
    "## Step 3: Building the Vector Database with Gemini Embeddings\n",
    "Now we'll create a vector database using Google's Gemini embeddings to store and retrieve our document chunks. This enables semantic search capabilities, allowing us to find the most relevant standard sections for a given financial transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5ef5ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing Chroma vector store...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tayeb Kahia\\AppData\\Local\\Temp\\ipykernel_19284\\1155358187.py:25: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_store = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store contains 1130 documents\n"
     ]
    }
   ],
   "source": [
    "# Define path for Chroma persistence\n",
    "CHROMA_PATH = \"../vector_db/standards_reverse_transactions_gemini\"\n",
    "\n",
    "# Initialize Gemini embeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/embedding-001\"  # Gemini embedding model\n",
    ")\n",
    "\n",
    "# Extract chunk texts and prepare metadata\n",
    "chunk_texts = [chunk[\"text\"] for chunk in chunks]\n",
    "chunk_metadatas = [\n",
    "    {\n",
    "        \"source\": chunk[\"source\"],\n",
    "        \"chunk_id\": chunk[\"chunk_id\"],\n",
    "        \"standard_type\": chunk[\"standard_type\"],\n",
    "        \"standard_number\": chunk[\"standard_number\"]\n",
    "    } \n",
    "    for chunk in chunks\n",
    "]\n",
    "\n",
    "# Check if the vector store already exists\n",
    "if os.path.exists(CHROMA_PATH):\n",
    "    # Load existing vector store\n",
    "    print(\"Loading existing Chroma vector store...\")\n",
    "    vector_store = Chroma(\n",
    "        persist_directory=CHROMA_PATH,\n",
    "        embedding_function=embeddings\n",
    "    )\n",
    "else:\n",
    "    # Create a new vector store\n",
    "    print(\"Creating new Chroma vector store...\")\n",
    "    vector_store = Chroma.from_texts(\n",
    "        texts=chunk_texts,\n",
    "        embedding=embeddings,\n",
    "        metadatas=chunk_metadatas,\n",
    "        persist_directory=CHROMA_PATH\n",
    "    )\n",
    "    # Persist the vector store to disk\n",
    "    vector_store.persist()\n",
    "    print(f\"Saved vector store to {CHROMA_PATH}\")\n",
    "    \n",
    "print(f\"Vector store contains {vector_store._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eee1a2",
   "metadata": {},
   "source": [
    "## Step 4: Retrieval Functions\n",
    "Let's create functions to retrieve the most relevant standards for a given financial transaction. These functions will help us find the right context to determine which FAS applies to a particular journal entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2429757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_standards(query, top_k=5):\n",
    "    \"\"\"\n",
    "    Retrieve the most relevant chunks from our vector store for a given query.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The text query about a financial transaction\n",
    "        top_k (int): Number of results to retrieve\n",
    "        \n",
    "    Returns:\n",
    "        list: List of document chunks with metadata\n",
    "    \"\"\"\n",
    "    # Use Chroma's similarity search to find relevant chunks\n",
    "    docs = vector_store.similarity_search(query, k=top_k)\n",
    "    \n",
    "    # Convert the returned documents to our expected format\n",
    "    results = []\n",
    "    for doc in docs:\n",
    "        results.append({\n",
    "            \"source\": doc.metadata[\"source\"],\n",
    "            \"standard_type\": doc.metadata[\"standard_type\"],\n",
    "            \"standard_number\": doc.metadata[\"standard_number\"],\n",
    "            \"text\": doc.page_content\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def filter_by_standard(results, standard_type=None, standard_number=None):\n",
    "    \"\"\"\n",
    "    Filter retrieved results by standard type and/or number.\n",
    "    \n",
    "    Args:\n",
    "        results (list): List of document chunks\n",
    "        standard_type (str, optional): Filter by standard type (FAS, SS)\n",
    "        standard_number (str, optional): Filter by standard number\n",
    "        \n",
    "    Returns:\n",
    "        list: Filtered list of document chunks\n",
    "    \"\"\"\n",
    "    filtered = results\n",
    "    \n",
    "    if standard_type:\n",
    "        filtered = [r for r in filtered if r[\"standard_type\"].upper() == standard_type.upper()]\n",
    "    \n",
    "    if standard_number:\n",
    "        filtered = [r for r in filtered if r[\"standard_number\"] == standard_number]\n",
    "        \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953d09bd",
   "metadata": {},
   "source": [
    "## Step 5: FAS Identification and Weighting using Gemini\n",
    "The core of our solution is the ability to identify which AAOIFI standards are most relevant to a given financial transaction. We'll use Google's Gemini model to analyze the transaction details and provide weighted probabilities for each potentially applicable standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e26727bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_transaction(transaction_description, journal_entry=None, top_k=10):  # Increased top_k for more comprehensive context\n",
    "    \"\"\"\n",
    "    Analyze a financial transaction and identify relevant AAOIFI standards using Gemini.\n",
    "    \n",
    "    Args:\n",
    "        transaction_description (str): Description of the transaction\n",
    "        journal_entry (str, optional): Journal entry related to the transaction\n",
    "        top_k (int): Number of relevant chunks to retrieve\n",
    "        \n",
    "    Returns:\n",
    "        dict: Analysis results with weighted probabilities\n",
    "    \"\"\"\n",
    "    # Construct a comprehensive query combining description and journal entry\n",
    "    query = transaction_description\n",
    "    if journal_entry:\n",
    "        query += f\"\\n{journal_entry}\"\n",
    "    \n",
    "    # Enhanced query construction with explicit accounting scenarios to improve retrieval\n",
    "    enhanced_query = f\"\"\"\n",
    "    Financial transaction analysis:\n",
    "    {query}\n",
    "    \n",
    "    Considering all possible accounting implications including:\n",
    "    - Ownership changes and consolidation requirements\n",
    "    - Contract modifications and reversals\n",
    "    - Revenue and cost recognition\n",
    "    - Asset recognition and classification\n",
    "    - Shariah compliance considerations\n",
    "    \n",
    "    Relevant AAOIFI Financial Accounting Standards (FAS) and Shariah Standards (SS)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve relevant chunks with increased top_k for more context\n",
    "    relevant_chunks = retrieve_relevant_standards(enhanced_query, top_k=top_k)\n",
    "    \n",
    "    # Filter to focus on FAS documents\n",
    "    fas_chunks = filter_by_standard(relevant_chunks, standard_type=\"FAS\")\n",
    "    \n",
    "    # Extract unique FAS numbers for consideration\n",
    "    potential_standards = []\n",
    "    seen_standards = set()\n",
    "    \n",
    "    for chunk in fas_chunks:\n",
    "        standard_id = f\"FAS {chunk['standard_number']}\"\n",
    "        if standard_id not in seen_standards and chunk['standard_number'] != \"Unknown\":\n",
    "            seen_standards.add(standard_id)\n",
    "            potential_standards.append({\n",
    "                \"id\": standard_id,\n",
    "                \"context\": chunk['text'][:500]  # Brief context from the standard\n",
    "            })\n",
    "    \n",
    "    # Key FAS standards to consider explicitly for all transactions\n",
    "    # This ensures important standards are considered even if not returned by vector search\n",
    "    key_fas_standards = [\"FAS 1\", \"FAS 2\", \"FAS 4\", \"FAS 10\", \"FAS 20\", \"FAS 28\", \"FAS 32\"]\n",
    "    \n",
    "    for standard in key_fas_standards:\n",
    "        if standard not in seen_standards:\n",
    "            # Add important standards even if not retrieved\n",
    "            potential_standards.append({\n",
    "                \"id\": standard,\n",
    "                \"context\": f\"This is a key AAOIFI standard that should be considered for completeness.\"\n",
    "            })\n",
    "            seen_standards.add(standard)\n",
    "    \n",
    "    # Also include SS standards as they often contain complementary guidance\n",
    "    ss_chunks = filter_by_standard(relevant_chunks, standard_type=\"SS\")\n",
    "    ss_references = []\n",
    "    \n",
    "    for chunk in ss_chunks:\n",
    "        standard_id = f\"SS {chunk['standard_number']}\"\n",
    "        if standard_id not in seen_standards and chunk['standard_number'] != \"Unknown\":\n",
    "            seen_standards.add(standard_id)\n",
    "            ss_references.append({\n",
    "                \"id\": standard_id,\n",
    "                \"context\": chunk['text'][:300]  # Brief context from the standard\n",
    "            })\n",
    "    \n",
    "    # Combine all relevant contexts for the LLM\n",
    "    context_text = \"\"\n",
    "    for std in potential_standards:\n",
    "        context_text += f\"Standard {std['id']}:\\n{std['context']}\\n\\n\"\n",
    "    \n",
    "    for std in ss_references:\n",
    "        context_text += f\"Supporting standard {std['id']}:\\n{std['context']}\\n\\n\"\n",
    "    \n",
    "    # Create Gemini LLM\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-1.5-pro\",\n",
    "        temperature=0,\n",
    "        convert_system_message_to_human=True\n",
    "    )\n",
    "    \n",
    "    # Create enhanced prompt template with better guidance for standard selection\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"transaction\", \"journal_entry\", \"context\", \"standard_ids\"],\n",
    "        template=\"\"\"\n",
    "    You are an expert in Islamic finance, AAOIFI standards, and accounting. You are tasked with analyzing financial transactions against AAOIFI standards.\n",
    "\n",
    "    Transaction description:\n",
    "    {transaction}\n",
    "    \n",
    "    Journal entry (if provided):\n",
    "    {journal_entry}\n",
    "    \n",
    "    Excerpts from potentially relevant standards:\n",
    "    {context}\n",
    "    \n",
    "    Potential standards to consider: {standard_ids}\n",
    "    \n",
    "    IMPORTANT ANALYSIS GUIDELINES:\n",
    "    1. Consider BOTH direct AND downstream implications of transactions (e.g., 100% ownership necessitates consolidation)\n",
    "    2. For ownership changes, particularly consider FAS 4 (Consolidation) and FAS 20 (Associates) when appropriate\n",
    "    3. For contract modifications or reversals, identify the core contract type (Istisna'a, Ijarah, Murabaha, etc.)\n",
    "    4. Look for key trigger phrases that indicate specific standards:\n",
    "       - 100% ownership → consolidation (FAS 4, FAS 20)\n",
    "       - Manufacturing/construction contracts → Istisna'a (FAS 10)\n",
    "       - Leasing → Ijarah (FAS 32)\n",
    "       - Deferred payment sales → Murabaha (FAS 28)\n",
    "    5. Assign accurate probabilities based on relevance to the specific transaction details\n",
    "    \n",
    "    Based on your analysis, provide the following in JSON format:\n",
    "    1. The FAS standards that apply to this transaction, with probability weights (0-100) totaling 100%\n",
    "    2. A brief reasoning for each standard's applicability or inapplicability\n",
    "    3. A determination if the journal entry appears to comply with the identified standards\n",
    "    4. Any relevant Shariah considerations from the SS standards\n",
    "    \n",
    "    Return only the JSON object without additional commentary. Example format:\n",
    "    {{\n",
    "      \"applicable_standards\": [\n",
    "        {{\n",
    "          \"standard\": \"FAS 28\",\n",
    "          \"probability\": 70,\n",
    "          \"reasoning\": \"This standard applies because...\"\n",
    "        }},\n",
    "        {{\n",
    "          \"standard\": \"FAS 30\",\n",
    "          \"probability\": 30,\n",
    "          \"reasoning\": \"This standard is somewhat relevant because...\"\n",
    "        }}\n",
    "      ],\n",
    "      \"compliance_assessment\": \"The journal entry appears to comply with FAS 28 because...\",\n",
    "      \"shariah_considerations\": \"According to SS 9, this transaction should also consider...\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    )\n",
    "    \n",
    "    # Prepare standard IDs for the prompt\n",
    "    standard_ids = \", \".join([std[\"id\"] for std in potential_standards])\n",
    "    \n",
    "    # Run the analysis\n",
    "    chain = prompt | llm\n",
    "    \n",
    "    # Invoke the chain\n",
    "    response = chain.invoke({\n",
    "        \"transaction\": transaction_description,\n",
    "        \"journal_entry\": journal_entry if journal_entry else \"No journal entry provided\",\n",
    "        \"context\": context_text,\n",
    "        \"standard_ids\": standard_ids\n",
    "    })\n",
    "    \n",
    "    # Extract content from response\n",
    "    if hasattr(response, 'content'):\n",
    "        response_text = response.content\n",
    "    else:\n",
    "        response_text = str(response)\n",
    "    \n",
    "    # Parse the JSON output\n",
    "    try:\n",
    "        result = json.loads(response_text)\n",
    "        \n",
    "        # Sort applicable standards by probability in descending order and filter out 0 probability standards\n",
    "        if \"applicable_standards\" in result:\n",
    "            result[\"applicable_standards\"] = [\n",
    "                standard for standard in result[\"applicable_standards\"] \n",
    "                if standard.get(\"probability\", 0) > 0\n",
    "            ]\n",
    "            result[\"applicable_standards\"].sort(key=lambda x: x.get(\"probability\", 0), reverse=True)\n",
    "        \n",
    "        return result\n",
    "    except json.JSONDecodeError:\n",
    "        # If parsing fails, try to extract JSON from the response\n",
    "        match = re.search(r'({.*})', response_text, re.DOTALL)\n",
    "        if match:\n",
    "            try:\n",
    "                json_result = json.loads(match.group(1))\n",
    "                \n",
    "                # Sort applicable standards by probability in descending order and filter out 0 probability standards\n",
    "                if \"applicable_standards\" in json_result:\n",
    "                    json_result[\"applicable_standards\"] = [\n",
    "                        standard for standard in json_result[\"applicable_standards\"] \n",
    "                        if standard.get(\"probability\", 0) > 0\n",
    "                    ]\n",
    "                    json_result[\"applicable_standards\"].sort(key=lambda x: x.get(\"probability\", 0), reverse=True)\n",
    "                \n",
    "                return json_result\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Return error if parsing fails\n",
    "        return {\n",
    "            \"error\": \"Failed to parse LLM response\",\n",
    "            \"raw_response\": response_text\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d894eee",
   "metadata": {},
   "source": [
    "## Step 6: Testing with Example Cases\n",
    "Let's test our implementation with the example cases provided in the hackathon challenge:\n",
    "\n",
    "### Example 1: GreenTech Exit and Buyout\n",
    "- Context: GreenTech exits in Year 3, and Al Baraka Bank buys out its stake\n",
    "- Adjustments: Buyout Price: $1,750,000; Bank Ownership: 100%\n",
    "- Journal Entry: Dr. GreenTech Equity $1,750,000 / Cr. Cash $1,750,000\n",
    "\n",
    "### Example 2: Contract Reversal\n",
    "- Context: Client cancels a change order, reverting to original contract terms\n",
    "- Adjustments: Revised Contract Value back to $5,000,000; Timeline Restored: 2 years\n",
    "- Journal Entry: Dr. Accounts Payable $1,000,000 / Cr. Work-in-Progress $1,000,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3403ed52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Test Case 1: GreenTech Exit and Buyout\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\course-env\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:390: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"applicable_standards\": [\n",
      "    {\n",
      "      \"standard\": \"FAS 4\",\n",
      "      \"probability\": 70,\n",
      "      \"reasoning\": \"FAS 4 (Consolidation) is highly relevant as Al Baraka Bank now owns 100% of GreenTech.  This triggers the requirement for consolidating GreenTech's financial statements into Al Baraka's.\"\n",
      "    },\n",
      "    {\n",
      "      \"standard\": \"FAS 1\",\n",
      "      \"probability\": 10,\n",
      "      \"reasoning\": \"FAS 1 (Presentation and Disclosure) is generally applicable to all financial transactions, including this acquisition, as it sets the overall framework for financial reporting.\"\n",
      "    },\n",
      "    {\n",
      "      \"standard\": \"FAS 2\",\n",
      "      \"probability\": 10,\n",
      "      \"reasoning\": \"FAS 2 (Accounting for Specific Items) might be relevant depending on the specific nature of GreenTech's assets and liabilities being acquired.  Further details are needed to assess its full applicability.\"\n",
      "    },\n",
      "    {\n",
      "      \"standard\": \"FAS 28\",\n",
      "      \"probability\": 10,\n",
      "      \"reasoning\": \"FAS 28 (Murabaha and Other Deferred Payment Sales) is not directly applicable to the buyout itself. However, if the acquisition was financed through a Murabaha or similar arrangement, then FAS 28 would be relevant to that financing transaction, not the acquisition accounting.\"\n",
      "    }\n",
      "  ],\n",
      "  \"compliance_assessment\": \"The provided journal entry is incomplete and does not comply with the relevant standards, particularly FAS 4.  Achieving 100% ownership requires consolidating GreenTech's assets and liabilities onto Al Baraka's balance sheet, not simply derecognizing the equity investment and recognizing an expense.  A full consolidation process is required under FAS 4.\",\n",
      "  \"shariah_considerations\": \"While not directly addressed in the provided information, the valuation of GreenTech for the buyout should be conducted in a Shariah-compliant manner, ensuring fairness and transparency.  Any underlying contracts or activities of GreenTech should also be reviewed for Shariah compliance after the acquisition.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test Case 1: GreenTech Exit and Buyout\n",
    "test_case_1 = {\n",
    "    \"description\": \"\"\"\n",
    "    GreenTech exits in Year 3, and Al Baraka Bank buys out its stake. \n",
    "    After this buyout, the bank's ownership becomes 100%. \n",
    "    The accounting treatment involves derecognition of GreenTech's equity and recognition of the acquisition expense.\n",
    "    \"\"\",\n",
    "    \"journal_entry\": \"Dr. GreenTech Equity $1,750,000 / Cr. Cash $1,750,000\"\n",
    "}\n",
    "\n",
    "# Run the analysis\n",
    "print(\"Analyzing Test Case 1: GreenTech Exit and Buyout\\n\")\n",
    "result_1 = analyze_transaction(test_case_1[\"description\"], test_case_1[\"journal_entry\"])\n",
    "\n",
    "# Display the results\n",
    "print(json.dumps(result_1, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6709a6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Test Case 2: Contract Reversal\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\course-env\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:390: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"applicable_standards\": [\n",
      "    {\n",
      "      \"standard\": \"FAS 10\",\n",
      "      \"probability\": 40,\n",
      "      \"reasoning\": \"If the original contract and the change order relate to construction or manufacturing, FAS 10 (Istisna'a) becomes highly relevant.  Reversing the change order would necessitate adjustments to the Istisna'a contract's accounting, including revenue and cost recognition.\"\n",
      "    },\n",
      "    {\n",
      "      \"standard\": \"FAS 1\",\n",
      "      \"probability\": 20,\n",
      "      \"reasoning\": \"This standard provides the general principles of accounting and should always be considered as a foundational standard for all transactions, including contract modifications.\"\n",
      "    },\n",
      "    {\n",
      "      \"standard\": \"FAS 2\",\n",
      "      \"probability\": 20,\n",
      "      \"reasoning\": \"This standard deals with accounting for inventories.  Given the reversal of costs related to the change order and its impact on work-in-progress, FAS 2 is relevant for the proper valuation and presentation of inventory affected by the contract revision.\"\n",
      "    },\n",
      "    {\n",
      "      \"standard\": \"FAS 32\",\n",
      "      \"probability\": 20,\n",
      "      \"reasoning\": \"This standard applies to Ijarah (leasing).  If the original contract and the change order involved a lease agreement, then FAS 32 becomes relevant.  The cancellation of the change order would require adjustments to the lease accounting in accordance with this standard.\"\n",
      "    }\n",
      "  ],\n",
      "  \"compliance_assessment\": \"The provided journal entry appears partially compliant.  Debiting Accounts Payable and crediting Work-in-Progress suggests a reversal of costs related to the change order. However, without knowing the original contract type (Istisna'a, Ijarah, etc.) and the specific accounting treatment applied to the change order, a full compliance assessment is not possible.  Further details are needed to determine the appropriate accounting treatment under the relevant FAS.\",\n",
      "  \"shariah_considerations\": \"While not directly addressed in the provided information, Shariah compliance requires that all contract modifications and cancellations adhere to the principles of fairness, transparency, and mutual consent.  Any unjust enrichment or undue hardship resulting from the change order reversal should be avoided.  The specific Shariah standards (SS) applicable would depend on the nature of the underlying contract (e.g., SS 8 for Istisna'a, SS 15 for Ijarah, SS 17 for Murabaha).\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test Case 2: Contract Reversal\n",
    "test_case_2 = {\n",
    "    \"description\": \"\"\"\n",
    "    The client decided to cancel a change order that had previously modified the contract terms. \n",
    "    This cancellation reverts all terms back to the original contract. \n",
    "    The contract value is revised back to $5,000,000, and the project timeline is restored to the original 2 years. \n",
    "    This requires adjustment of revenue and cost projections, as well as a reversal of additional cost accruals.\n",
    "    \"\"\",\n",
    "    \"journal_entry\": \"Dr. Accounts Payable $1,000,000 / Cr. Work-in-Progress $1,000,000\"\n",
    "}\n",
    "\n",
    "# Run the analysis\n",
    "print(\"Analyzing Test Case 2: Contract Reversal\\n\")\n",
    "result_2 = analyze_transaction(test_case_2[\"description\"], test_case_2[\"journal_entry\"])\n",
    "\n",
    "# Display the results\n",
    "print(json.dumps(result_2, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
