{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4485e13",
   "metadata": {},
   "source": [
    "# Challenge 3: Standard Enhancement Multi-Agent System\n",
    "\n",
    "## Overview\n",
    "This notebook implements the multi-agent AI system for reviewing, suggesting, and validating updates to AAOIFI standards as specified in Challenge 3 of the hackathon.\n",
    "\n",
    "### System Architecture\n",
    "Our solution employs a sophisticated multi-agent architecture designed for the nuanced analysis and enhancement of Islamic financial standards. Each agent is specialized in a distinct aspect of standards processing:\n",
    "\n",
    "We'll focus on developing three specialized agents:\n",
    "1. **Review & Extraction Agent**: Processes the selected standards to extract key elements, definitions, principles, scope, recognition criteria, measurement rules, and disclosure requirements.\n",
    "2. **Enhancement Agent**: Suggests modifications/enhancements by comparing with other standards, analyzing contemporary financial instruments, and identifying improvement areas.\n",
    "3. **Validation Agent**: Validates proposed changes for compliance with AAOIFI principles and Shariah requirements.\n",
    "\n",
    "### Data Flow\n",
    "- **Input**: AAOIFI Financial Accounting Standards (FAS) documents\n",
    "- **Processing**: Sequential processing through our three specialized agents\n",
    "- **Output**: Comprehensive analysis, enhancement suggestions, and validation results\n",
    "\n",
    "### Standards Selection\n",
    "For this implementation, we'll focus on **multiple standards** to demonstrate the system's versatility:\n",
    "- **FAS 4** (Murabaha and Murabaha to the Purchase Orderer)\n",
    "- **FAS 10** (Istisna'a and Parallel Istisna'a)\n",
    "- **FAS 32** (Ijarah and Ijarah Muntahia Bittamleek)\n",
    "\n",
    "These standards represent diverse Islamic financial instruments, providing a robust test for our system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b4d8d7",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, let's import the necessary libraries and initialize our environment. Our system requires:\n",
    "\n",
    "- **Standard libraries**: For file handling, data structures, and typing\n",
    "- **LangChain components**: For building our Retrieval-Augmented Generation (RAG) system\n",
    "- **Google Gemini integration**: For state-of-the-art language model capabilities\n",
    "- **Vector database**: For efficient document retrieval\n",
    "\n",
    "We'll also set up important configurations like project paths and API validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e7a03f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda\\envs\\chall3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_community.tools import BaseTool\n",
    "from langchain.schema import BaseMessage, AIMessage, HumanMessage\n",
    "\n",
    "# Load environment variables (for Google API key)\n",
    "load_dotenv()\n",
    "\n",
    "# Configure paths\n",
    "notebook_dir = Path(__file__).parent if \"__file__\" in globals() else Path.cwd()\n",
    "project_root = notebook_dir.parent.parent  # Go up two levels from notebooks/callenge3 to project root\n",
    "data_dir = project_root / \"data\"\n",
    "vector_db_dir = project_root / \"vector_db\" / \"standards_enhancement\"\n",
    "\n",
    "# Check if Google API key is set\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    raise ValueError(\"GOOGLE_API_KEY environment variable is not set. Please set it to use Gemini models.\")\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb4f21",
   "metadata": {},
   "source": [
    "## 2. PDF Processing and Vector DB Setup\n",
    "\n",
    "A critical component of our system is the ability to process and understand complex financial standard documents. To accomplish this, we'll:\n",
    "\n",
    "1. **Load PDF documents**: Process all relevant AAOIFI standards\n",
    "2. **Extract and enrich metadata**: Identify standard types, numbers, and source information\n",
    "3. **Split into semantic chunks**: Break documents into manageable pieces while preserving meaning\n",
    "4. **Create vector embeddings**: Using Google's Gemini embedding model for semantic understanding\n",
    "5. **Build a vector database**: For efficient similarity search and context retrieval\n",
    "\n",
    "This approach allows our agents to quickly access the most relevant parts of the standards when performing analysis and making recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a55b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading C:\\Users\\Zinou\\OneDrive\\Desktop\\2CS_IASD\\ISDB\\isdb-hackthon\\data\\FAS10.PDF...\n",
      "Split 42 pages into 151 chunks\n",
      "Loading C:\\Users\\Zinou\\OneDrive\\Desktop\\2CS_IASD\\ISDB\\isdb-hackthon\\data\\FAS 10 & SS 11.pdf...\n",
      "Split 42 pages into 151 chunks\n",
      "Loading C:\\Users\\Zinou\\OneDrive\\Desktop\\2CS_IASD\\ISDB\\isdb-hackthon\\data\\FAS 10 & SS 11.pdf...\n",
      "Split 23 pages into 23 chunks\n",
      "Loading C:\\Users\\Zinou\\OneDrive\\Desktop\\2CS_IASD\\ISDB\\isdb-hackthon\\data\\SS9.pdf...\n",
      "Split 23 pages into 23 chunks\n",
      "Loading C:\\Users\\Zinou\\OneDrive\\Desktop\\2CS_IASD\\ISDB\\isdb-hackthon\\data\\SS9.pdf...\n",
      "Split 34 pages into 157 chunks\n",
      "Loading C:\\Users\\Zinou\\OneDrive\\Desktop\\2CS_IASD\\ISDB\\isdb-hackthon\\data\\SS12.pdf...\n",
      "Split 34 pages into 157 chunks\n",
      "Loading C:\\Users\\Zinou\\OneDrive\\Desktop\\2CS_IASD\\ISDB\\isdb-hackthon\\data\\SS12.pdf...\n",
      "Split 70 pages into 307 chunks\n",
      "Loading C:\\Users\\Zinou\\OneDrive\\Desktop\\2CS_IASD\\ISDB\\isdb-hackthon\\data\\FAS32.pdf...\n",
      "Split 70 pages into 307 chunks\n",
      "Loading C:\\Users\\Zinou\\OneDrive\\Desktop\\2CS_IASD\\ISDB\\isdb-hackthon\\data\\FAS32.pdf...\n",
      "Split 41 pages into 142 chunks\n",
      "Loading C:\\Users\\Zinou\\OneDrive\\Desktop\\2CS_IASD\\ISDB\\isdb-hackthon\\data\\FAS4.PDF...\n",
      "Split 41 pages into 142 chunks\n",
      "Loading C:\\Users\\Zinou\\OneDrive\\Desktop\\2CS_IASD\\ISDB\\isdb-hackthon\\data\\FAS4.PDF...\n",
      "Split 30 pages into 118 chunks\n",
      "Split 30 pages into 118 chunks\n",
      "Created vector DB with 898 chunks using Gemini embeddings\n",
      "Created vector DB with 898 chunks using Gemini embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zinou\\AppData\\Local\\Temp\\ipykernel_11828\\3383905415.py:80: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vector_db.persist()\n"
     ]
    }
   ],
   "source": [
    "def process_pdf(pdf_path):\n",
    "    \"\"\"Load and split a PDF into chunks.\n",
    "    \n",
    "    This function processes a PDF file by:\n",
    "    1. Loading the document page by page\n",
    "    2. Extracting metadata from the filename\n",
    "    3. Adding metadata to each page\n",
    "    4. Splitting into semantically meaningful chunks\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "        \n",
    "    Returns:\n",
    "        List of document chunks with metadata\n",
    "    \"\"\"\n",
    "    # Load PDF\n",
    "    print(f\"Loading {pdf_path}...\")\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    pages = loader.load()\n",
    "    \n",
    "    # Extract metadata from filename\n",
    "    filename = os.path.basename(pdf_path)\n",
    "    standard_type = \"FAS\" if \"FAS\" in filename else \"SS\"\n",
    "    standard_num = \"\".join(filter(str.isdigit, filename))\n",
    "    \n",
    "    # Add metadata to pages\n",
    "    for page in pages:\n",
    "        page.metadata[\"standard_type\"] = standard_type\n",
    "        page.metadata[\"standard_num\"] = standard_num\n",
    "        page.metadata[\"source\"] = filename\n",
    "        # Keep existing page number metadata\n",
    "    \n",
    "    # Split into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \";\", \",\", \" \", \"\"]\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(pages)\n",
    "    print(f\"Split {len(pages)} pages into {len(chunks)} chunks\")\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def create_vector_db():\n",
    "    \"\"\"Process PDF files and create a vector database using Gemini embeddings.\n",
    "    \n",
    "    This function:\n",
    "    1. Checks for existing vector database to avoid reprocessing\n",
    "    2. Processes multiple standards PDFs (FAS and Shariah Standards)\n",
    "    3. Creates embeddings using Google's Gemini model\n",
    "    4. Builds and persists a Chroma vector database\n",
    "    \n",
    "    Returns:\n",
    "        Chroma vector database instance for document retrieval\n",
    "    \"\"\"\n",
    "    # Create vector DB directory if it doesn't exist\n",
    "    vector_db_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Check if vector DB already exists\n",
    "    if os.path.exists(vector_db_dir / \"chroma.sqlite3\"):\n",
    "        print(\"Vector DB already exists. Loading existing DB...\")\n",
    "        # Setup Gemini embeddings\n",
    "        embeddings = GoogleGenerativeAIEmbeddings(\n",
    "            model=\"models/embedding-001\"  # Gemini embedding model\n",
    "        )\n",
    "        # Load existing DB\n",
    "        vector_db = Chroma(embedding_function=embeddings, persist_directory=str(vector_db_dir))\n",
    "        return vector_db\n",
    "    \n",
    "    # Process standard files (focusing on FAS 10 and related SS)\n",
    "    pdf_files = [\n",
    "        data_dir / \"FAS10.PDF\",\n",
    "        data_dir / \"FAS 10 & SS 11.pdf\",  # Related Shariah Standard\n",
    "        data_dir / \"SS9.pdf\",  # Related Shariah Standard\n",
    "        data_dir / \"SS12.pdf\",  # Related Shariah Standard\n",
    "        data_dir / \"FAS32.pdf\",  # For comparison\n",
    "        data_dir / \"FAS4.PDF\"    # For comparison\n",
    "    ]\n",
    "    \n",
    "    # Process each PDF and collect all chunks\n",
    "    all_chunks = []\n",
    "    for pdf_file in pdf_files:\n",
    "        if pdf_file.exists():\n",
    "            chunks = process_pdf(str(pdf_file))\n",
    "            all_chunks.extend(chunks)\n",
    "        else:\n",
    "            print(f\"Warning: {pdf_file} not found\")\n",
    "    \n",
    "    if not all_chunks:\n",
    "        raise ValueError(\"No documents were processed. Check file paths.\")\n",
    "    \n",
    "    # Setup Gemini embeddings\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(\n",
    "        model=\"models/embedding-001\"  # Gemini embedding model\n",
    "    )\n",
    "    \n",
    "    # Create vector DB\n",
    "    vector_db = Chroma.from_documents(\n",
    "        documents=all_chunks,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=str(vector_db_dir)\n",
    "    )\n",
    "    vector_db.persist()\n",
    "    print(f\"Created vector DB with {len(all_chunks)} chunks using Gemini embeddings\")\n",
    "    \n",
    "    return vector_db\n",
    "\n",
    "# Create or load the vector database\n",
    "vector_db = create_vector_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715d9740",
   "metadata": {},
   "source": [
    "## 3. Define the Multi-Agent System\n",
    "\n",
    "Our solution's core is a sophisticated multi-agent system designed for collaborative intelligence. Each agent has specialized capabilities but works as part of an integrated system.\n",
    "\n",
    "The agents communicate through a sequential process where:\n",
    "- Output from the Review Agent becomes input for the Enhancement Agent\n",
    "- Output from both becomes input for the Validation Agent\n",
    "\n",
    "### Key Components:\n",
    "1. **Language Model**: Google's Gemini 1.5 Pro for advanced reasoning\n",
    "2. **Vector Retrieval**: For providing relevant context to each agent\n",
    "3. **Specialized Prompts**: Custom instructions for each agent's unique role\n",
    "4. **Pipelines**: Structured data flow between system components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb6a262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Gemini LLM\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",  # Using Gemini's most capable model\n",
    "    temperature=0,          # Setting temperature to 0 for maximum determinism\n",
    "    convert_system_message_to_human=True  # Required for Gemini compatibility\n",
    ")\n",
    "\n",
    "# Create a retriever from the vector DB\n",
    "# This retriever uses similarity search to find the most relevant context\n",
    "# from our standards database when prompted by an agent\n",
    "retriever = vector_db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 6}  # Retrieve more documents for comprehensive analysis\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12a8d4c",
   "metadata": {},
   "source": [
    "### 3.1 Agent 1: Review & Extraction Agent\n",
    "\n",
    "The first agent in our system serves as the foundation for subsequent analysis. This agent has three critical responsibilities:\n",
    "\n",
    "1. **Deep Document Analysis**: Thoroughly parsing standard documents to understand their structure and content\n",
    "2. **Key Element Extraction**: Identifying and extracting specific components like definitions, principles, recognition criteria, etc.\n",
    "3. **Ambiguity Detection**: Identifying areas that may be unclear or open to interpretation\n",
    "\n",
    "The agent uses a specialized prompt template that guides it through this structured analysis process. The retrieved context provides the necessary information about the standard being analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddab142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Review & Extraction Agent\n",
    "\n",
    "# This template guides the agent to extract specific elements from a standard\n",
    "# The structured approach ensures consistency across different standards\n",
    "review_template = \"\"\"\n",
    "You are a specialized AI agent for reviewing and extracting key information from AAOIFI Financial Accounting Standards (FAS).\n",
    "Your task is to comprehensively analyze the standard {standard_name} and extract its key elements.\n",
    "\n",
    "Based on the following context information about the standard, please extract and organize the following elements:\n",
    "\n",
    "Context information:\n",
    "{context}\n",
    "\n",
    "Please extract and organize the following:\n",
    "\n",
    "1. Definitions of key terms in {standard_name}\n",
    "2. Scope and applicability of the standard\n",
    "3. Core principles and concepts\n",
    "4. Recognition criteria for contracts/transactions covered by this standard\n",
    "5. Measurement rules and methodologies\n",
    "6. Disclosure requirements\n",
    "7. Areas that are potentially unclear or ambiguous\n",
    "8. Special cases or exceptions mentioned\n",
    "\n",
    "Format your response as a detailed structured analysis that another AI agent could use to propose improvements.\n",
    "\"\"\"\n",
    "\n",
    "# Create the RAG pipeline for the Review Agent\n",
    "# This is a Retrieval-Augmented Generation (RAG) chain that:\n",
    "# 1. Takes a standard name as input\n",
    "# 2. Retrieves relevant context from our vector database\n",
    "# 3. Formats the prompt with the standard name and context\n",
    "# 4. Sends the prompt to our LLM\n",
    "# 5. Extracts the response as a string\n",
    "review_prompt = ChatPromptTemplate.from_template(review_template)\n",
    "review_chain = (\n",
    "    {\"context\": lambda x: retriever.invoke(f\"Analyze and extract key elements from {x['standard_name']}\"), \n",
    "     \"standard_name\": lambda x: x[\"standard_name\"]}\n",
    "    | review_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Function to run the review agent\n",
    "def run_review_agent(standard_name):\n",
    "    \"\"\"Run the review agent to extract information from the standard.\n",
    "    \n",
    "    Args:\n",
    "        standard_name: Name of the standard to analyze (e.g., \"FAS 10 (Istisna'a and Parallel Istisna'a)\")\n",
    "        \n",
    "    Returns:\n",
    "        Structured analysis of the standard as text\n",
    "    \"\"\"\n",
    "    return review_chain.invoke({\"standard_name\": standard_name})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485897a5",
   "metadata": {},
   "source": [
    "### 3.2 Agent 2: Enhancement Agent\n",
    "\n",
    "The second agent in our system takes the output from the Review Agent and proposes meaningful improvements. This agent focuses on:\n",
    "\n",
    "1. **Gap Analysis**: Identifying areas where the standard could be improved\n",
    "2. **Contemporary Relevance**: Suggesting updates to align with modern financial practices\n",
    "3. **Clarity Improvements**: Proposing clearer language and additional examples\n",
    "4. **Global Alignment**: Identifying opportunities for harmonization with global standards while maintaining Shariah compliance\n",
    "\n",
    "This agent combines the structured analysis from the Review Agent with additional comparative context to generate specific, actionable enhancement proposals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597b100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Enhancement Agent\n",
    "\n",
    "# This template provides detailed instructions for suggesting improvements\n",
    "# It structures the enhancement process into 8 key areas\n",
    "enhancement_template = \"\"\"\n",
    "You are a specialized AI agent for suggesting improvements to AAOIFI Financial Accounting Standards (FAS).\n",
    "Your task is to analyze the extracted information from {standard_name} and suggest meaningful enhancements.\n",
    "\n",
    "Standard information extracted by the Review Agent:\n",
    "{standard_info}\n",
    "\n",
    "Additional context from related standards:\n",
    "{context}\n",
    "\n",
    "Please propose enhancements in the following areas:\n",
    "\n",
    "1. Clarifications for ambiguous or unclear sections\n",
    "2. Additional examples or illustrations for complex concepts\n",
    "3. Updates to align with contemporary financial instruments or practices\n",
    "4. Potential harmonization with global standards (like IFRS) while maintaining Shariah compliance\n",
    "5. Additional guidance for practical implementation\n",
    "6. Improvements to disclosure requirements\n",
    "7. Addressing gaps in coverage of specific transaction types\n",
    "8. Enhanced structure or organization for better usability\n",
    "\n",
    "For each enhancement suggestion:\n",
    "- Clearly identify the specific section/aspect of {standard_name} being addressed\n",
    "- Explain the current limitation or issue\n",
    "- Provide the proposed enhancement with specific wording where appropriate\n",
    "- Justify why this enhancement would improve the standard's usability or effectiveness\n",
    "\n",
    "IMPORTANT: Ensure all suggestions maintain Shariah compliance and align with Islamic financial principles.\n",
    "\"\"\"\n",
    "\n",
    "# Create the RAG pipeline for the Enhancement Agent\n",
    "# This chain:\n",
    "# 1. Takes standard info from the Review Agent and the standard name\n",
    "# 2. Retrieves comparative context from related standards\n",
    "# 3. Generates enhancement suggestions using all available information\n",
    "enhancement_prompt = ChatPromptTemplate.from_template(enhancement_template)\n",
    "enhancement_chain = (\n",
    "    {\"context\": lambda x: retriever.invoke(f\"Comparative analysis of {x['standard_name']} with other standards\"), \n",
    "     \"standard_info\": lambda x: x[\"standard_info\"],\n",
    "     \"standard_name\": lambda x: x[\"standard_name\"]}\n",
    "    | enhancement_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Function to run the enhancement agent\n",
    "def run_enhancement_agent(standard_info, standard_name):\n",
    "    \"\"\"Run the enhancement agent to suggest improvements to the standard.\n",
    "    \n",
    "    Args:\n",
    "        standard_info: Structured analysis from the Review Agent\n",
    "        standard_name: Name of the standard being enhanced\n",
    "        \n",
    "    Returns:\n",
    "        Proposed enhancements as structured text\n",
    "    \"\"\"\n",
    "    return enhancement_chain.invoke({\"standard_info\": standard_info, \"standard_name\": standard_name})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f56f0d",
   "metadata": {},
   "source": [
    "### 3.3 Agent 3: Validation Agent\n",
    "\n",
    "The final agent in our system serves as a critical safeguard for Shariah compliance and practicality. This agent:\n",
    "\n",
    "1. **Evaluates Compliance**: Assesses whether proposed enhancements maintain or improve Shariah compliance\n",
    "2. **Checks Consistency**: Ensures alignment with AAOIFI's overall framework\n",
    "3. **Assesses Practicality**: Evaluates whether suggestions can be realistically implemented\n",
    "4. **Makes Recommendations**: Approves, suggests modifications, or rejects each proposal\n",
    "\n",
    "This validation step is crucial to ensure that all enhancements meet the unique requirements of Islamic financial standards. The agent provides detailed justification for each decision, creating transparency in the validation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd499343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Validation Agent\n",
    "\n",
    "# This template guides the validation process with specific criteria\n",
    "# It ensures all proposed enhancements meet Shariah requirements\n",
    "validation_template = \"\"\"\n",
    "You are a specialized AI agent for validating proposed enhancements to AAOIFI Financial Accounting Standards (FAS).\n",
    "Your task is to evaluate the suggested improvements to {standard_name} for compliance with Shariah principles and AAOIFI's overall framework.\n",
    "\n",
    "Standard information extracted by the Review Agent:\n",
    "{standard_info}\n",
    "\n",
    "Proposed enhancements from the Enhancement Agent:\n",
    "{enhancements}\n",
    "\n",
    "Additional context from Shariah standards:\n",
    "{context}\n",
    "\n",
    "Please validate each proposed enhancement by assessing:\n",
    "\n",
    "1. Shariah Compliance: Does the enhancement maintain or improve compliance with Islamic financial principles?\n",
    "2. Consistency: Is it consistent with AAOIFI's overall framework and other standards?\n",
    "3. Practicality: Would it be practical to implement in real-world Islamic financial institutions?\n",
    "4. Clarity: Does it enhance or maintain the clarity of the standard?\n",
    "5. Relevance: Is it relevant to contemporary Islamic finance practices?\n",
    "6. Thoroughness: Does it address the identified issue comprehensively?\n",
    "\n",
    "For each enhancement:\n",
    "- Provide a rating (Approved, Approved with Modifications, or Rejected)\n",
    "- Justify your decision with specific references to Shariah principles or AAOIFI requirements where applicable\n",
    "- For 'Approved with Modifications', suggest the specific modifications needed\n",
    "- For 'Rejected', explain the specific issues that make the enhancement inappropriate\n",
    "\n",
    "Conclude with a summary of which enhancements should be adopted, modified, or rejected.\n",
    "\"\"\"\n",
    "\n",
    "# Create the RAG pipeline for the Validation Agent\n",
    "# This chain:\n",
    "# 1. Takes inputs from both previous agents and the standard name\n",
    "# 2. Retrieves Shariah-specific context for validation\n",
    "# 3. Evaluates each enhancement against Shariah principles\n",
    "# 4. Produces a detailed validation report\n",
    "validation_prompt = ChatPromptTemplate.from_template(validation_template)\n",
    "validation_chain = (\n",
    "    {\"context\": lambda x: retriever.invoke(f\"Shariah compliance of {x['standard_name']} proposed enhancements\"), \n",
    "     \"standard_info\": lambda x: x[\"standard_info\"], \n",
    "     \"enhancements\": lambda x: x[\"enhancements\"],\n",
    "     \"standard_name\": lambda x: x[\"standard_name\"]}\n",
    "    | validation_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Function to run the validation agent\n",
    "def run_validation_agent(standard_info, enhancements, standard_name):\n",
    "    \"\"\"Run the validation agent to evaluate proposed enhancements.\n",
    "    \n",
    "    Args:\n",
    "        standard_info: Structured analysis from the Review Agent\n",
    "        enhancements: Proposed improvements from the Enhancement Agent\n",
    "        standard_name: Name of the standard being evaluated\n",
    "        \n",
    "    Returns:\n",
    "        Validation results as structured text\n",
    "    \"\"\"\n",
    "    return validation_chain.invoke({\"standard_info\": standard_info, \"enhancements\": enhancements, \"standard_name\": standard_name})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b3f427",
   "metadata": {},
   "source": [
    "## 4. Multi-Agent Orchestration\n",
    "\n",
    "Orchestration is critical for our multi-agent system to function effectively. This component:\n",
    "\n",
    "1. **Coordinates Agent Workflow**: Manages the sequential process from review to enhancement to validation\n",
    "2. **Handles Data Transfer**: Ensures each agent has the inputs it needs from previous agents\n",
    "3. **Processes Multiple Standards**: Applies the workflow to each selected standard\n",
    "4. **Consolidates Results**: Aggregates findings from all standards into a comprehensive output\n",
    "\n",
    "The orchestration layer ensures our agents work together as an integrated system rather than isolated components. This coordinated approach allows for more sophisticated analysis than any single agent could provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e478f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multi_agent_system():\n",
    "    \"\"\"Run the complete multi-agent system for standard enhancement.\n",
    "    \n",
    "    This function orchestrates the entire multi-agent process by:\n",
    "    1. Processing multiple standards sequentially\n",
    "    2. Running each agent in the proper order for each standard\n",
    "    3. Passing outputs between agents\n",
    "    4. Storing and saving all results\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing all results for all standards\n",
    "    \"\"\"\n",
    "    # Define the standards to analyze\n",
    "    standards = [\n",
    "        \"FAS 4 (Murabaha and Murabaha to the Purchase Orderer)\",\n",
    "        \"FAS 10 (Istisna'a and Parallel Istisna'a)\",\n",
    "        \"FAS 32 (Ijarah and Ijarah Muntahia Bittamleek)\"\n",
    "    ]\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    for standard in standards:\n",
    "        print(f\"\\nStarting Multi-Agent System for {standard} Enhancement...\\n\")\n",
    "        \n",
    "        # Step 1: Run the Review & Extraction Agent\n",
    "        print(f\"AGENT 1 (Review & Extraction): Analyzing {standard}...\")\n",
    "        standard_info = run_review_agent(standard)\n",
    "        print(\"\\nReview & Extraction Complete!\\n\")\n",
    "        \n",
    "        # Step 2: Run the Enhancement Agent\n",
    "        print(f\"AGENT 2 (Enhancement): Suggesting improvements to {standard}...\")\n",
    "        enhancements = run_enhancement_agent(standard_info, standard)\n",
    "        print(\"\\nEnhancement Suggestions Complete!\\n\")\n",
    "        \n",
    "        # Step 3: Run the Validation Agent\n",
    "        print(f\"AGENT 3 (Validation): Evaluating proposed enhancements for {standard} for Shariah compliance...\")\n",
    "        validation_results = run_validation_agent(standard_info, enhancements, standard)\n",
    "        print(\"\\nValidation Complete!\\n\")\n",
    "        \n",
    "        # Store results for this standard\n",
    "        # Create a standardized key format (e.g., \"FAS4\", \"FAS10\")\n",
    "        standard_key = standard.split(' ')[0] + standard.split(' ')[1].strip('()')\n",
    "        all_results[standard_key] = {\n",
    "            \"standard_name\": standard,\n",
    "            \"standard_info\": standard_info,\n",
    "            \"enhancements\": enhancements,\n",
    "            \"validation_results\": validation_results\n",
    "        }\n",
    "    \n",
    "    # Save all results to file in JSON format for later analysis and visualization\n",
    "    output_path = project_root / \"notebooks\" / \"fas_enhancement_results.json\"\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e300e4e2",
   "metadata": {},
   "source": [
    "## 5. Run the Multi-Agent System\n",
    "\n",
    "With our agents defined and orchestration in place, we're ready to execute the complete system. This process will:\n",
    "\n",
    "1. **Process Multiple Standards**: Apply our multi-agent analysis to FAS 4, 10, and 32\n",
    "2. **Generate Comprehensive Output**: Produce detailed analysis, enhancement suggestions, and validation for each standard\n",
    "3. **Save Results**: Store all outputs in a structured JSON format for downstream applications\n",
    "\n",
    "This execution represents the culmination of our multi-agent design, demonstrating how AI can assist in the complex task of enhancing Islamic financial standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0930d43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Multi-Agent System for FAS 4 (Murabaha and Murabaha to the Purchase Orderer) Enhancement...\n",
      "\n",
      "AGENT 1 (Review & Extraction): Analyzing FAS 4 (Murabaha and Murabaha to the Purchase Orderer)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda\\envs\\chall3\\lib\\site-packages\\langchain_google_genai\\chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Review & Extraction Complete!\n",
      "\n",
      "AGENT 2 (Enhancement): Suggesting improvements to FAS 4 (Murabaha and Murabaha to the Purchase Orderer)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda\\envs\\chall3\\lib\\site-packages\\langchain_google_genai\\chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enhancement Suggestions Complete!\n",
      "\n",
      "AGENT 3 (Validation): Evaluating proposed enhancements for FAS 4 (Murabaha and Murabaha to the Purchase Orderer) for Shariah compliance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda\\envs\\chall3\\lib\\site-packages\\langchain_google_genai\\chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Complete!\n",
      "\n",
      "\n",
      "Starting Multi-Agent System for FAS 10 (Istisna'a and Parallel Istisna'a) Enhancement...\n",
      "\n",
      "AGENT 1 (Review & Extraction): Analyzing FAS 10 (Istisna'a and Parallel Istisna'a)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda\\envs\\chall3\\lib\\site-packages\\langchain_google_genai\\chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Review & Extraction Complete!\n",
      "\n",
      "AGENT 2 (Enhancement): Suggesting improvements to FAS 10 (Istisna'a and Parallel Istisna'a)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda\\envs\\chall3\\lib\\site-packages\\langchain_google_genai\\chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enhancement Suggestions Complete!\n",
      "\n",
      "AGENT 3 (Validation): Evaluating proposed enhancements for FAS 10 (Istisna'a and Parallel Istisna'a) for Shariah compliance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda\\envs\\chall3\\lib\\site-packages\\langchain_google_genai\\chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Complete!\n",
      "\n",
      "\n",
      "Starting Multi-Agent System for FAS 32 (Ijarah and Ijarah Muntahia Bittamleek) Enhancement...\n",
      "\n",
      "AGENT 1 (Review & Extraction): Analyzing FAS 32 (Ijarah and Ijarah Muntahia Bittamleek)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda\\envs\\chall3\\lib\\site-packages\\langchain_google_genai\\chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Review & Extraction Complete!\n",
      "\n",
      "AGENT 2 (Enhancement): Suggesting improvements to FAS 32 (Ijarah and Ijarah Muntahia Bittamleek)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda\\envs\\chall3\\lib\\site-packages\\langchain_google_genai\\chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enhancement Suggestions Complete!\n",
      "\n",
      "AGENT 3 (Validation): Evaluating proposed enhancements for FAS 32 (Ijarah and Ijarah Muntahia Bittamleek) for Shariah compliance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda\\envs\\chall3\\lib\\site-packages\\langchain_google_genai\\chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Complete!\n",
      "\n",
      "\n",
      "==== MULTI-AGENT SYSTEM RESULTS ====\n",
      "\n",
      "\n",
      "----- FAS 4 (Murabaha and Murabaha to the Purchase Orderer) -----\n",
      "\n",
      "Standard Information Extracted:\n",
      "\n",
      "## Analysis of AAOIFI FAS 4 (Murabaha and Murabaha to the Purchase Orderer) based on provided context\n",
      "\n",
      "The provided context offers limited information specifically about the *content* of FAS 4. It primarily focuses on the standard's development history and its grouping with other standards like Mush...\n",
      "\n",
      "Enhancements Proposed:\n",
      "\n",
      "## Proposed Enhancements to AAOIFI FAS 4 (Murabaha and Murabaha to the Purchase Orderer)\n",
      "\n",
      "The following enhancements are proposed to improve the clarity, applicability, and effectiveness of FAS 4 while maintaining Shariah compliance:\n",
      "\n",
      "**1. Clarifications for Ambiguous or Unclear Sections:**\n",
      "\n",
      "* **Sec...\n",
      "\n",
      "Validation Results:\n",
      "\n",
      "## Validation of Proposed Enhancements to AAOIFI FAS 4\n",
      "\n",
      "Here's an evaluation of the proposed enhancements to FAS 4, considering Shariah compliance, consistency, practicality, clarity, relevance, and thoroughness:\n",
      "\n",
      "**1. Clarifications for Ambiguous or Unclear Sections:**\n",
      "\n",
      "* **Definition of \"Cost\":** ...\n",
      "\n",
      "\n",
      "----- FAS 10 (Istisna'a and Parallel Istisna'a) -----\n",
      "\n",
      "Standard Information Extracted:\n",
      "\n",
      "## Analysis of AAOIFI FAS 10 (Istisna'a and Parallel Istisna'a)\n",
      "\n",
      "This analysis extracts key elements from the provided context information, acknowledging its limitations due to the absence of the full text of FAS 10.  Therefore, many sections will be marked as requiring further information.\n",
      "\n",
      "**1. De...\n",
      "\n",
      "Enhancements Proposed:\n",
      "\n",
      "## Enhancements to AAOIFI FAS 10 (Istisna'a and Parallel Istisna'a)\n",
      "\n",
      "**1. Clarifications for ambiguous or unclear sections:**\n",
      "\n",
      "* **Section:** Definitions of Istisna'a and Parallel Istisna'a\n",
      "* **Issue:** Lack of clear definitions.\n",
      "* **Enhancement:** Provide comprehensive definitions, including key el...\n",
      "\n",
      "Validation Results:\n",
      "\n",
      "## Validation of Proposed Enhancements to AAOIFI FAS 10\n",
      "\n",
      "Here's an evaluation of the proposed enhancements to FAS 10, considering Shariah compliance, consistency, practicality, clarity, relevance, and thoroughness.\n",
      "\n",
      "**1. Clarifications for ambiguous or unclear sections (Definitions)**\n",
      "\n",
      "* **Rating:**...\n",
      "\n",
      "\n",
      "----- FAS 32 (Ijarah and Ijarah Muntahia Bittamleek) -----\n",
      "\n",
      "Standard Information Extracted:\n",
      "\n",
      "## Analysis of AAOIFI FAS 32 (Ijarah and Ijarah Muntahia Bittamleek)\n",
      "\n",
      "This analysis extracts key elements from the provided context regarding FAS 32, focusing on improvements from its predecessor, FAS 8.  Due to the limited context, some sections will remain incomplete and marked as such.  Further d...\n",
      "\n",
      "Enhancements Proposed:\n",
      "\n",
      "## Proposed Enhancements to AAOIFI FAS 32 (Ijarah and Ijarah Muntahia Bittamleek)\n",
      "\n",
      "These enhancements aim to clarify, expand, and update FAS 32 while maintaining Shariah compliance.\n",
      "\n",
      "**1. Clarifications for Ambiguous or Unclear Sections:**\n",
      "\n",
      "* **Section:** Definitions (Ijarah, IMBT, Operating Ijarah)...\n",
      "\n",
      "Validation Results:\n",
      "\n",
      "## Validation of Proposed Enhancements to AAOIFI FAS 32\n",
      "\n",
      "Here's an evaluation of the proposed enhancements to FAS 32, considering Shariah compliance, consistency, practicality, clarity, relevance, and thoroughness.\n",
      "\n",
      "**1. Clarifications for Ambiguous or Unclear Sections (Definitions)**\n",
      "\n",
      "* **Rating:**...\n",
      "\n",
      "\n",
      "Full results saved to 'fas_enhancement_results.json'\n"
     ]
    }
   ],
   "source": [
    "# Run the full multi-agent system\n",
    "results = run_multi_agent_system()\n",
    "\n",
    "# Display summary of results\n",
    "print(\"\\n==== MULTI-AGENT SYSTEM RESULTS ====\\n\")\n",
    "\n",
    "for standard_key, standard_results in results.items():\n",
    "    print(f\"\\n----- {standard_results['standard_name']} -----\\n\")\n",
    "    print(\"Standard Information Extracted:\\n\")\n",
    "    print(standard_results[\"standard_info\"][:300] + \"...\\n\")\n",
    "    \n",
    "    print(\"Enhancements Proposed:\\n\")\n",
    "    print(standard_results[\"enhancements\"][:300] + \"...\\n\")\n",
    "    \n",
    "    print(\"Validation Results:\\n\")\n",
    "    print(standard_results[\"validation_results\"][:300] + \"...\\n\")\n",
    "\n",
    "print(\"\\nFull results saved to 'fas_enhancement_results.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c81d44",
   "metadata": {},
   "source": [
    "## 6. Interactive Query System\n",
    "\n",
    "Beyond the core analysis, our system includes an interactive query capability that allows users to:\n",
    "\n",
    "1. **Ask Questions**: Query specific aspects of the enhanced standards\n",
    "2. **Access Insights**: Get detailed information about proposed enhancements and their validation\n",
    "3. **Compare Standards**: Explore differences and similarities between different FAS\n",
    "\n",
    "This component transforms our system from a one-time analysis tool into an ongoing knowledge resource that stakeholders can use to understand the nuances of Islamic financial standards and our proposed enhancements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ac058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the template for our query system\n",
    "# This template allows flexible questioning about any enhanced standard\n",
    "query_template = \"\"\"\n",
    "You are an AI assistant specialized in AAOIFI standards, particularly the Financial Accounting Standards (FAS).\n",
    "Use the following information to answer the user's question about {standard_name}:\n",
    "\n",
    "Standard Information:\n",
    "{standard_info}\n",
    "\n",
    "Proposed Enhancements:\n",
    "{enhancements}\n",
    "\n",
    "Validation Results:\n",
    "{validation_results}\n",
    "\n",
    "Additional Context from Standards:\n",
    "{context}\n",
    "\n",
    "User Question: {question}\n",
    "\n",
    "Provide a detailed, accurate response. If the user's question relates to a proposed enhancement,\n",
    "make sure to indicate whether that enhancement was approved or not during validation.\n",
    "\"\"\"\n",
    "\n",
    "# Create a function to query a specific standard\n",
    "def create_query_chain(standard_key):\n",
    "    \"\"\"Create a query chain for a specific standard.\n",
    "    \n",
    "    This function creates a specialized chain for each standard that:\n",
    "    1. Loads the standard's data\n",
    "    2. Retrieves relevant context based on the query\n",
    "    3. Formats all information for the LLM\n",
    "    4. Returns a detailed response\n",
    "    \n",
    "    Args:\n",
    "        standard_key: The key for the standard (e.g., \"FAS4\")\n",
    "        \n",
    "    Returns:\n",
    "        A runnable chain for querying the standard\n",
    "    \"\"\"\n",
    "    standard_data = results[standard_key]\n",
    "    query_prompt = ChatPromptTemplate.from_template(query_template)\n",
    "    return (\n",
    "        {\"context\": lambda x: retriever.invoke(f\"Information about {standard_data['standard_name']}\"), \n",
    "         \"standard_info\": lambda x: standard_data[\"standard_info\"], \n",
    "         \"enhancements\": lambda x: standard_data[\"enhancements\"], \n",
    "         \"validation_results\": lambda x: standard_data[\"validation_results\"],\n",
    "         \"standard_name\": lambda x: standard_data[\"standard_name\"],\n",
    "         \"question\": RunnablePassthrough()}\n",
    "        | query_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "# Dictionary of query chains for each standard\n",
    "query_chains = {}\n",
    "for standard_key in results.keys():\n",
    "    query_chains[standard_key] = create_query_chain(standard_key)\n",
    "\n",
    "def query_enhanced_standard(standard_key, question):\n",
    "    \"\"\"Query the enhanced standard with a specific question.\n",
    "    \n",
    "    Args:\n",
    "        standard_key: Key for the standard to query (e.g., \"FAS4\")\n",
    "        question: The user's question about the standard\n",
    "        \n",
    "    Returns:\n",
    "        Detailed response to the question\n",
    "    \"\"\"\n",
    "    if standard_key not in query_chains:\n",
    "        return f\"Error: Standard '{standard_key}' not found. Available standards are: {', '.join(query_chains.keys())}\"\n",
    "    return query_chains[standard_key].invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b777e4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===== QUERYING FAS4 =====\n",
      "\n",
      "\n",
      "Question: What are the main improvements suggested for FAS 4?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda\\envs\\chall3\\lib\\site-packages\\langchain_google_genai\\chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: The provided documents do *not* contain proposed enhancements to FAS 4 (Murabaha and Murabaha to the Purchase Orderer).  The documents *do* discuss the *history* of FAS 4's development, mentioning it was grouped with standards on Musharaka and Mudaraba for initial development.  Other documents provide information on FAS 32 (Ijarah) and SS 12 (Mudaraba), but not proposed changes to FAS 4 itself.\n",
      "\n",
      "Therefore, I cannot answer your question about the main improvements suggested for FAS 4 based on the...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Question: How does FAS 4 handle revenue recognition in Murabaha contracts?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda\\envs\\chall3\\lib\\site-packages\\langchain_google_genai\\chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: The provided text excerpts from FAS 4 do *not* contain information about revenue recognition for Murabaha contracts. The excerpts focus on the standard's development history and mention Murabaha and Murabaha to the Purchase Orderer as initial areas of focus, but do not delve into the standard's specific content regarding revenue recognition or any other accounting treatment.  FAS 4, as titled in the provided excerpts, pertains to *Musharaka* financing, not Murabaha.  There appears to be a discre...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Question: What challenges exist in the current standard regarding Murabaha to the Purchase Orderer?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda\\envs\\chall3\\lib\\site-packages\\langchain_google_genai\\chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: The provided texts do not offer specific details about challenges related to *Murabaha to the Purchase Orderer* within FAS 4. The excerpts primarily focus on the standard's development history and general principles of Murabaha.  Therefore, it's impossible to pinpoint specific challenges based on the given context.\n",
      "\n",
      "However, the *Proposed Enhancements* section identifies a potential challenge related to the complexity of *Murabaha to the Purchase Orderer* due to its tripartite nature.  It sugges...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "===== QUERYING FAS10 =====\n",
      "\n",
      "\n",
      "Question: What are the main improvements suggested for FAS 10?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda\\envs\\chall3\\lib\\site-packages\\langchain_google_genai\\chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: The proposed improvements to AAOIFI FAS 10 (Istisna'a and Parallel Istisna'a) aim to enhance its clarity, comprehensiveness, and practical application while maintaining Shariah compliance.  Here's a breakdown of the key suggested enhancements and their validation status:\n",
      "\n",
      "**Approved Enhancements:**\n",
      "\n",
      "* **Clearer Definitions:** Providing comprehensive definitions of Istisna'a and Parallel Istisna'a, including key elements like customization, payment terms, ownership transfer, and distinctions from...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Question: How does FAS 10 handle revenue recognition in Istisna'a contracts?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda\\envs\\chall3\\lib\\site-packages\\langchain_google_genai\\chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: The provided text does *not* contain specific details on how FAS 10 handles revenue recognition for Istisna'a contracts.  While the analysis mentions that the standard likely covers profit recognition, the precise methodology is not described.  The full text of FAS 10 is required to answer this question accurately.\n",
      "\n",
      "However, the proposed enhancements *do* address revenue recognition:\n",
      "\n",
      "**Proposed Enhancement:** Harmonization with IFRS 15 (Revenue Recognition) - adapting a five-step model for reve...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Question: What challenges exist in the current standard regarding parallel Istisna'a?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda\\envs\\chall3\\lib\\site-packages\\langchain_google_genai\\chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: The primary challenge in the current FAS 10 regarding Parallel Istisna'a is the **lack of clear definition and guidance**.  While the standard mentions Parallel Istisna'a and provides some examples in the appendices, it doesn't offer a precise definition of what constitutes Parallel Istisna'a, the specific circumstances under which it is permissible, or the detailed accounting treatment required.  This lack of clarity creates several issues:\n",
      "\n",
      "* **Difficulty in distinguishing Parallel Istisna'a f...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "===== QUERYING FAS32 =====\n",
      "\n",
      "\n",
      "Question: What are the main improvements suggested for FAS 32?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda\\envs\\chall3\\lib\\site-packages\\langchain_google_genai\\chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: The main improvements suggested for FAS 32 \"Ijarah and Ijarah Muntahia Bittamleek\" focus on enhancing clarity, aligning with contemporary practices, and improving practical application.  These proposed enhancements, and their validation status, are as follows:\n",
      "\n",
      "**Approved Enhancements:**\n",
      "\n",
      "* **Clearer Definitions:** Providing explicit definitions for Ijarah, IMBT, and Operating Ijarah. This was a key area of ambiguity identified in the review.  The proposed definitions were *approved* during vali...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Question: How does FAS 32 handle recognition of Ijarah assets?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda\\envs\\chall3\\lib\\site-packages\\langchain_google_genai\\chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: The provided text from FAS 32 does *not* specify the recognition criteria for Ijarah assets.  The analysis correctly identifies this as a gap in the standard.  It *does* mention the need to identify and separate Ijarah components within a contract, suggesting that recognition likely involves this step, but the specific criteria are not defined.\n",
      "\n",
      "However, a *proposed enhancement* to FAS 32 addresses this gap:\n",
      "\n",
      "**5. Additional Guidance for Practical Implementation (Recognition Criteria)**\n",
      "\n",
      "* **Enh...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Question: What challenges exist in the current standard regarding Ijarah Muntahia Bittamleek?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda\\envs\\chall3\\lib\\site-packages\\langchain_google_genai\\chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: The primary challenge identified in the current standard (FAS 8) regarding Ijarah Muntahia Bittamleek (IMBT), as implied by the provided context from FAS 32, is a lack of clarity and comprehensive guidance, especially in comparison to evolving industry practices and global accounting standards.  While FAS 8 does address IMBT, the decision to supersede it with FAS 32 suggests several shortcomings.  These challenges are not explicitly listed but can be inferred from the focus of the proposed enhan...\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate the query system with example questions for each standard\n",
    "# This shows how our system can answer specific questions about each standard\n",
    "for standard_key in results.keys():\n",
    "    print(f\"\\n\\n===== QUERYING {standard_key} =====\\n\")\n",
    "    \n",
    "    # Define standard-specific questions that demonstrate system capabilities\n",
    "    if standard_key == \"FAS4\":\n",
    "        questions = [\n",
    "            \"What are the main improvements suggested for FAS 4?\",  # Overview of enhancements\n",
    "            \"How does FAS 4 handle revenue recognition in Murabaha contracts?\",  # Specific technical aspect\n",
    "            \"What challenges exist in the current standard regarding Murabaha to the Purchase Orderer?\"  # Problem identification\n",
    "        ]\n",
    "    elif standard_key == \"FAS10\":\n",
    "        questions = [\n",
    "            \"What are the main improvements suggested for FAS 10?\",  # Overview of enhancements\n",
    "            \"How does FAS 10 handle revenue recognition in Istisna'a contracts?\",  # Specific technical aspect\n",
    "            \"What challenges exist in the current standard regarding parallel Istisna'a?\"  # Problem identification\n",
    "        ]\n",
    "    elif standard_key == \"FAS32\":\n",
    "        questions = [\n",
    "            \"What are the main improvements suggested for FAS 32?\",  # Overview of enhancements\n",
    "            \"How does FAS 32 handle recognition of Ijarah assets?\",  # Specific technical aspect\n",
    "            \"What challenges exist in the current standard regarding Ijarah Muntahia Bittamleek?\"  # Problem identification\n",
    "        ]\n",
    "    \n",
    "    # Run the queries and display truncated results\n",
    "    for question in questions:\n",
    "        print(f\"\\nQuestion: {question}\")\n",
    "        answer = query_enhanced_standard(standard_key, question)\n",
    "        print(f\"\\nAnswer: {answer[:500]}...\\n\")\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf59e0a3",
   "metadata": {},
   "source": [
    "## 7. Conclusion and Next Steps\n",
    "\n",
    "### Achievements\n",
    "Our multi-agent system successfully accomplishes the challenge of enhancing AAOIFI Financial Accounting Standards through AI-powered analysis. Key achievements include:\n",
    "\n",
    "1. **Comprehensive Standard Analysis**: Detailed extraction of key components from complex financial standards\n",
    "2. **Meaningful Enhancement Proposals**: Concrete suggestions that improve clarity, practicality, and contemporary relevance\n",
    "3. **Shariah-Compliant Validation**: Thorough evaluation ensuring all enhancements maintain Islamic financial principles\n",
    "4. **Multiple Standard Processing**: Demonstrated versatility by successfully handling three different standards\n",
    "5. **Interactive Knowledge Access**: Creation of a query system to access insights about enhanced standards\n",
    "\n",
    "### Value to Stakeholders\n",
    "This system provides significant value to various stakeholders in the Islamic finance ecosystem:\n",
    "\n",
    "- **Standards Bodies**: Accelerated standards development and enhancement process\n",
    "- **Financial Institutions**: Clearer understanding and implementation of standards\n",
    "- **Regulators**: More precise and comprehensive standards for oversight\n",
    "- **Educators and Students**: Improved learning resources with clearer explanations\n",
    "\n",
    "### Potential Next Steps\n",
    "To further develop this system, we could consider:\n",
    "\n",
    "1. **Extending the System**: Adding support for additional AAOIFI standards and Shariah Standards\n",
    "2. **Improving the Retrieval System**: Implementing more sophisticated chunking and embedding approaches\n",
    "3. **Adding Specialized Agents**: Creating agents for specific aspects like translation or examples generation\n",
    "4. **Developing a Visual Interface**: Building a user-friendly interface for interacting with the system (a basic implementation is provided in the Streamlit app)\n",
    "5. **Implementing Continuous Improvement**: Adding a feedback mechanism to incorporate user insights\n",
    "6. **Integration with Standards Development Process**: Embedding the system into the official standards development workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61d463f",
   "metadata": {},
   "source": [
    "## Required Libraries\n",
    "\n",
    "### Development Environment\n",
    "This notebook has been developed and tested with the following environment:\n",
    "\n",
    "- **Python**: 3.9+\n",
    "- **LangChain**: For agent construction, RAG pipeline, and orchestration\n",
    "- **Google Generative AI**: For Gemini model access for both LLM and embeddings\n",
    "- **ChromaDB**: For vector database functionality\n",
    "- **PDF Processing**: For handling standard documents\n",
    "\n",
    "### Installation Instructions\n",
    "To run this notebook with Gemini models, you need to install the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3137b314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation commands\n",
    "\n",
    "# Using pip\n",
    "!pip install langchain langchain-core langchain-community python-dotenv\n",
    "!pip install google-generativeai langchain-google-genai\n",
    "!pip install chromadb\n",
    "!pip install pypdf pdfplumber\n",
    "\n",
    "# Using conda\n",
    "# conda install -c conda-forge langchain python-dotenv\n",
    "# conda install -c conda-forge chromadb\n",
    "# conda install -c conda-forge google-generativeai \n",
    "# conda install -c conda-forge pypdf pdfplumber\n",
    "\n",
    "# Note: You'll need to set up the GOOGLE_API_KEY in your environment variables\n",
    "# or in a .env file in the project root directory:\n",
    "# GOOGLE_API_KEY=your_api_key_here\n",
    "\n",
    "# Additional required packages for the Streamlit visualization app:\n",
    "# !pip install streamlit\n",
    "# Run the viewer with: streamlit run fas_enhancement_viewer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e91eac1",
   "metadata": {},
   "source": [
    "## 8. Visualization with Streamlit\n",
    "\n",
    "To complement our analysis system, we've created a Streamlit application that visualizes the results. This application:\n",
    "\n",
    "1. **Presents Standard Analysis**: Shows the structured information extracted by our Review Agent\n",
    "2. **Displays Enhancement Proposals**: Presents the suggestions from our Enhancement Agent\n",
    "3. **Summarizes Validation Results**: Clearly indicates which enhancements were approved, modified, or rejected\n",
    "4. **Provides Search Functionality**: Allows users to search across all standards and results\n",
    "\n",
    "### Running the Visualization App\n",
    "\n",
    "To view the results in a user-friendly interface:\n",
    "\n",
    "1. Install Streamlit: `pip install streamlit`\n",
    "2. Navigate to the notebook directory\n",
    "3. Run: `streamlit run fas_enhancement_viewer.py`\n",
    "\n",
    "This creates an interactive web application that provides a more accessible way to explore the multi-agent system's outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde0e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample screenshot of the Streamlit app\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    # Path to a screenshot of the app (if available)\n",
    "    # display(Image(\"fas_viewer_screenshot.png\"))\n",
    "    # If no screenshot is available:\n",
    "    print(\"Visualization App Features:\")\n",
    "    print(\"- Tab-based interface for standard information, enhancements, and validation results\")\n",
    "    print(\"- Color-coded display of approved, modified, and rejected enhancements\")\n",
    "    print(\"- Search functionality across all standards\")\n",
    "    print(\"- Sidebar navigation between different standards\")\n",
    "    print(\"- Expandable sections for detailed information\")\n",
    "    print(\"\\nRun 'streamlit run fas_enhancement_viewer.py' to launch the interactive app\")\n",
    "except:\n",
    "    print(\"Visualization app screenshot not available. Run the app using streamlit to see the interface.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chall3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
